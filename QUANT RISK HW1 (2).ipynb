{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19358ba",
   "metadata": {},
   "source": [
    "Exercise 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "204c46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log, sqrt, exp, erf\n",
    "from datetime import datetime\n",
    "\n",
    "def norm_cdf(x):\n",
    "    return 0.5 * (1.0 + erf(x / sqrt(2.0)))\n",
    "\n",
    "def bs_price(S, K, T, r, q, sigma, callput):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        if callput.lower().startswith(\"c\"):\n",
    "            return max(S * exp(-q*T) - K * exp(-r*T), 0.0)\n",
    "        else:\n",
    "            return max(K * exp(-r*T) - S * exp(-q*T), 0.0)\n",
    "    d1 = (log(S / K) + (r - q + 0.5 * sigma**2) * T) / (sigma * sqrt(T))\n",
    "    d2 = d1 - sigma * sqrt(T)\n",
    "    if callput.lower().startswith(\"c\"):\n",
    "        return S * exp(-q*T) * norm_cdf(d1) - K * exp(-r*T) * norm_cdf(d2)\n",
    "    else:\n",
    "        return K * exp(-r*T) * norm_cdf(-d2) - S * exp(-q*T) * norm_cdf(-d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae482b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"OptionsPivotTables.xlsx\"\n",
    "raw = pd.read_excel(path, sheet_name=\"OptionsData\")\n",
    "# Extract value date from header row\n",
    "value_date = None\n",
    "for c in raw.columns:\n",
    "    if isinstance(c, (pd.Timestamp, datetime)):\n",
    "        value_date = pd.Timestamp(c).normalize()\n",
    "        break\n",
    "# Rebuild proper table\n",
    "header = raw.iloc[2].tolist()\n",
    "df = raw.iloc[3:].copy()\n",
    "df.columns = header\n",
    "underlying_row = df[df.get(\"Security Type\", \"\").eq(\"Future\")].head(1)\n",
    "if not underlying_row.empty:\n",
    "    S0 = float(underlying_row[\"Underlying Price\"].iloc[0])\n",
    "    q = float(underlying_row[\"Div. Yield\"].iloc[0])\n",
    "else:\n",
    "    S0 = float(df[\"Underlying Price\"].dropna().iloc[0])\n",
    "    q = float(df[\"Div. Yield\"].dropna().iloc[0])\n",
    "T = (pd.to_datetime(df[\"Maturity\"]) - value_date).dt.days / 365.25\n",
    "\n",
    "# Scenarios\n",
    "price_shifts = [-0.20, -0.15, -0.05, 0.0, 0.05, 0.10, 0.20]    \n",
    "vol_point_shifts = [-5, -2, 0, 2, 5, 15, 20]                   \n",
    "vol_shifts = [v / 100.0 for v in vol_point_shifts]\n",
    "scenario_cols = [f\"PnL: Und {int(ps*100):+d}% | Vol {vpp:+d}pp\"\n",
    "                 for ps in price_shifts for vpp in vol_point_shifts]\n",
    "scenario_df = pd.DataFrame(index=df.index, columns=scenario_cols, dtype=float)\n",
    "\n",
    "# Extract key columns\n",
    "positions = pd.to_numeric(df[\"Position\"], errors=\"coerce\").fillna(0.0).values\n",
    "strikes   = pd.to_numeric(df[\"Strike\"], errors=\"coerce\").values\n",
    "impvols   = pd.to_numeric(df[\"Imp. Vol\"], errors=\"coerce\").values\n",
    "rates     = pd.to_numeric(df[\"Risk-Free Rate\"], errors=\"coerce\").fillna(0.0).values\n",
    "opt_px0   = pd.to_numeric(df[\"Security Price\"], errors=\"coerce\").values\n",
    "mats      = T.values\n",
    "types     = df[\"Security Type\"].astype(str).values\n",
    "cpflag    = df[\"CallPut\"].astype(str).values\n",
    "\n",
    "# Calculate P&L for each scenario\n",
    "for ps in price_shifts:\n",
    "    S_scn = S0 * (1.0 + ps)\n",
    "    for vpp, vs in zip(vol_point_shifts, vol_shifts):\n",
    "        col = f\"PnL: Und {int(ps*100):+d}% | Vol {vpp:+d}pp\"\n",
    "        pnl = np.full_like(positions, np.nan, dtype=float)\n",
    "        mask_opt = (types == \"Option\")\n",
    "        if mask_opt.any():\n",
    "            sigma_new = np.maximum(impvols[mask_opt] + vs, 1e-6)\n",
    "            K = strikes[mask_opt]\n",
    "            T = np.maximum(mats[mask_opt], 1e-8)\n",
    "            r = rates[mask_opt]\n",
    "            cp = cpflag[mask_opt]\n",
    "            px0 = opt_px0[mask_opt]\n",
    "            pos = positions[mask_opt]\n",
    "            px_new = np.array([\n",
    "                bs_price(S_scn, K[i], T[i], r[i], q, sigma_new[i], cp[i])\n",
    "                for i in range(K.shape[0])\n",
    "            ])\n",
    "            pnl[mask_opt] = pos * (px_new - px0)\n",
    "        mask_fut = (types == \"Future\")\n",
    "        if mask_fut.any():\n",
    "            fut_px0 = pd.to_numeric(df.loc[mask_fut, \"Security Price\"], errors=\"coerce\").values\n",
    "            fut_pos = positions[mask_fut]\n",
    "            pnl[mask_fut] = fut_pos * (S_scn - fut_px0)\n",
    "        scenario_df[col] = pnl\n",
    "\n",
    "# Write back to Excel (starting at column AR) \n",
    "with pd.ExcelWriter(path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n",
    "    scenario_df.to_excel(writer, sheet_name=\"OptionsData\", startrow=2, startcol=43, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd1103",
   "metadata": {},
   "source": [
    "Exercise 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f0ac5",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "914df836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"OptionsPivotTables(updated).xlsx\"\n",
    "df = pd.read_excel(path, sheet_name=\"OptionsData\", header=3)\n",
    "# Create pivot table: Strike (rows), Maturity (columns), filter by Underlying\n",
    "pivot_table_spx = pd.pivot_table(\n",
    "    df[df[\"Underlying\"] == \"SPX Index\"],\n",
    "    values=scenario_col,\n",
    "    index=\"Strike\",\n",
    "    columns=\"Maturity\",\n",
    "    aggfunc=\"sum\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6710a0",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed35b8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Strike   Maturity     Delta     Gamma    Vega1%     Volga       Vanna\n",
      "1    935.0 2010-03-19 -0.216957  0.001091  1.480864  1.159981 -324.148692\n",
      "2   1001.0 2010-03-19 -0.294830  0.001448  1.738205  0.632473 -257.129811\n",
      "3   1100.0 2010-03-19 -0.464638  0.001916  1.999385 -0.042610  110.721229\n",
      "4   1034.0 2010-03-19 -0.344834  0.001632  1.855584  0.313724 -172.826343\n",
      "5   1232.0 2010-03-19  0.281636  0.001758  1.701222  1.928693  731.221049\n",
      "6   1100.0 2010-03-19  0.531154  0.001916  1.999385 -0.042610  110.721229\n",
      "7   1034.0 2010-03-19 -0.344834  0.001632  1.855584  0.313724 -172.826343\n",
      "8   1034.0 2010-03-19 -0.344834  0.001632  1.855584  0.313724 -172.826343\n",
      "9   1100.0 2010-03-19  0.531154  0.001916  1.999385 -0.042610  110.721229\n",
      "10  1232.0 2010-03-19  0.281636  0.001758  1.701222  1.928693  731.221049\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import log, sqrt, exp\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Since the given workbook does not really compute the greeks, we do this manually \n",
    "def bs_greeks(S, K, T, r, q, sigma, callput):\n",
    "    if pd.isna(K) or pd.isna(T) or pd.isna(r) or pd.isna(sigma):\n",
    "        return (np.nan,)*5\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return (np.nan,)*5\n",
    "    \n",
    "    d1 = (log(S/K) + (r - q + 0.5*sigma**2)*T) / (sigma*sqrt(T))\n",
    "    d2 = d1 - sigma*sqrt(T)\n",
    "    pdf = norm.pdf(d1)\n",
    "    \n",
    "    if str(callput).lower().startswith(\"c\"):\n",
    "        delta = exp(-q*T) * norm.cdf(d1)\n",
    "    else:\n",
    "        delta = -exp(-q*T) * norm.cdf(-d1)\n",
    "    \n",
    "    gamma = exp(-q*T) * pdf / (S * sigma * sqrt(T))\n",
    "    vega1 = 0.01 * S * exp(-q*T) * pdf * sqrt(T)\n",
    "    volga = vega1 * d1 * d2 / sigma\n",
    "    vanna = - (d2 / sigma) * S * exp(-q*T) * pdf\n",
    "    \n",
    "    return (delta, gamma, vega1, volga, vanna)\n",
    "\n",
    "S0 = float(df[\"Underlying Price\"].iloc[0])\n",
    "q  = float(df[\"Div. Yield\"].iloc[0])\n",
    "value_date = pd.to_datetime(\"2010-01-01\")\n",
    "T = (pd.to_datetime(df[\"Maturity\"]) - value_date).dt.days / 365.25\n",
    "\n",
    "greek_results = [\n",
    "    bs_greeks(S0, row[\"Strike\"], T_i, row[\"Risk-Free Rate\"], q, row[\"Imp. Vol\"], row[\"CallPut\"])\n",
    "    if row[\"Security Type\"]==\"Option\" else (np.nan,)*5\n",
    "    for (_, row), T_i in zip(df.iterrows(), T)\n",
    "]\n",
    "\n",
    "df[[\"Delta\",\"Gamma\",\"Vega1%\",\"Volga\",\"Vanna\"]] = pd.DataFrame(greek_results, index=df.index)\n",
    "print(df.loc[df[\"Security Type\"]==\"Option\",\n",
    "             [\"Strike\",\"Maturity\",\"Delta\",\"Gamma\",\"Vega1%\",\"Volga\",\"Vanna\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ad933fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Strike   Maturity  Scenario_PnL  Taylor_Approx    Difference\n",
      "1    935.0 2010-03-19  22659.491423   14366.306123   8293.185300\n",
      "2   1001.0 2010-03-19  -6807.212455   11448.391210 -18255.603665\n",
      "3   1100.0 2010-03-19   4263.761578   -4683.160743   8946.922321\n",
      "4   1034.0 2010-03-19  -3700.186730    7756.826354 -11457.013084\n",
      "5   1232.0 2010-03-19   -437.656553  -32159.077499  31721.420946\n",
      "6   1100.0 2010-03-19  -1213.062140   -4902.235112   3689.172972\n",
      "7   1034.0 2010-03-19  -7400.373461    7756.826354 -15157.199815\n",
      "8   1034.0 2010-03-19  -7400.373461    7756.826354 -15157.199815\n",
      "9   1100.0 2010-03-19   2426.124280   -4902.235112   7328.359392\n",
      "10  1232.0 2010-03-19   -525.187863  -32159.077499  31633.889635\n"
     ]
    }
   ],
   "source": [
    "# Taylor Approximation\n",
    "scenario_col = \"PnL: Und -20% | Vol +20\"\n",
    "dS = -0.20 * S0       \n",
    "dVol = 0.20          \n",
    "\n",
    "df[\"Taylor_Approx\"] = (\n",
    "    dS * df[\"Delta\"] +\n",
    "    0.5 * (dS**2) * df[\"Gamma\"] +\n",
    "    dVol * df[\"Vega1%\"] * 100 + \n",
    "    0.5 * (dVol**2) * df[\"Volga\"] +\n",
    "    dS * dVol * df[\"Vanna\"])\n",
    "\n",
    "# Compare\n",
    "df[\"Scenario_PnL\"] = df[scenario_col]\n",
    "df[\"Difference\"] = df[\"Scenario_PnL\"] - df[\"Taylor_Approx\"]\n",
    "\n",
    "print(df.loc[df[\"Security Type\"]==\"Option\",\n",
    "             [\"Strike\",\"Maturity\",\"Scenario_PnL\",\"Taylor_Approx\",\"Difference\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b5e39",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b7a424",
   "metadata": {},
   "source": [
    "No, because the current way that the OptionsData worksheet is organized isn’t well suited to building a pivot table that treats the underlying shift and the volatility shift as separate dimensions. In a pivot table we need these shifts to exist as separate columns instead of being joined in the same column (which rather represents a scenario).\n",
    "\n",
    "To make such a pivot table possible, the data would have needed to be stored in “long format”. Instead of 49 extra columns, there would be three extra columns, one column recording the underlying price shift, one column recording the volatility shift, and one column recording the P&L. Then each row of the table would represent the P&L of a single option under a single stress scenario (so the number of rows shall multiply by 49 because there is 49 scenarios for each single option (row)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b50796",
   "metadata": {},
   "source": [
    "Exercise 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec504eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   α (confidence)  VaR Normal   ES Normal  ES/VaR Normal       VaR t5  \\\n",
      "0        0.900000  162.104875  221.989782       1.369421   144.606514   \n",
      "1        0.950000  208.059355  260.914825       1.254040   197.433613   \n",
      "2        0.975000  247.918013  295.711262       1.192778   251.864554   \n",
      "3        0.990000  294.262316  337.125896       1.145665   329.694461   \n",
      "4        0.995000  325.819499  365.805779       1.122725   395.067715   \n",
      "5        0.999000  390.886903  425.906949       1.089591   577.435807   \n",
      "6        0.999900  470.422510  500.712473       1.064389   948.203976   \n",
      "7        0.999990  539.470755  566.519890       1.050140  1523.274429   \n",
      "8        0.999999  601.265900  625.920080       1.041004  2427.055329   \n",
      "\n",
      "         ES t5  ES/VaR t5  \n",
      "0   225.571541   1.559899  \n",
      "1   283.173648   1.434273  \n",
      "2   345.042702   1.369953  \n",
      "3   436.247178   1.323186  \n",
      "4   514.395845   1.302045  \n",
      "5   736.253644   1.275040  \n",
      "6  1194.204614   1.259439  \n",
      "7  1909.698023   1.253680  \n",
      "8  3037.345314   1.251453  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from scipy.stats import norm, t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "mu = 0.0\n",
    "annual_vol = 0.2\n",
    "trading_days = 250\n",
    "scale_multiplier = 10000  # to make numbers readable\n",
    "\n",
    "sigma_L = annual_vol / sqrt(trading_days) * scale_multiplier  # daily σ\n",
    "nu = 5  # degrees of freedom for Student's t\n",
    "\n",
    "# For the t distribution, scale so that Var(L_t) = sigma_L^2\n",
    "sigma_t_scale = sigma_L * sqrt((nu - 2) / nu)\n",
    "\n",
    "# Confidence levels as given\n",
    "alphas = np.array([0.90, 0.95, 0.975, 0.99, 0.995, 0.999, 0.9999, 0.99999, 0.999999])\n",
    "\n",
    "# ES functions\n",
    "def ES_normal(mu, sigma, alpha):\n",
    "    z = norm.ppf(alpha)\n",
    "    return mu + sigma * norm.pdf(z) / (1 - alpha)\n",
    "\n",
    "def ES_student_t(mu, scale, nu, alpha):\n",
    "    q = t.ppf(alpha, df=nu)\n",
    "    g = t.pdf(q, df=nu)\n",
    "    ES_std_t = g * (nu + q**2) / ((nu - 1) * (1 - alpha))\n",
    "    return mu + scale * ES_std_t\n",
    "\n",
    "# Compute table\n",
    "rows = []\n",
    "for a in alphas:\n",
    "    # Normal\n",
    "    var_norm = mu + sigma_L * norm.ppf(a)\n",
    "    es_norm = ES_normal(mu, sigma_L, a)\n",
    "    ratio_norm = es_norm / var_norm if var_norm != 0 else np.nan\n",
    "\n",
    "    # Student-t\n",
    "    var_t = mu + sigma_t_scale * t.ppf(a, df=nu)\n",
    "    es_t = ES_student_t(mu, sigma_t_scale, nu, a)\n",
    "    ratio_t = es_t / var_t if var_t != 0 else np.nan\n",
    "\n",
    "    rows.append([a, var_norm, es_norm, ratio_norm, var_t, es_t, ratio_t])\n",
    "\n",
    "result_df = pd.DataFrame(rows, columns=[\n",
    "    \"α (confidence)\", \"VaR Normal\", \"ES Normal\", \"ES/VaR Normal\", \"VaR t5\", \"ES t5\", \"ES/VaR t5\"\n",
    "])\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d866c7",
   "metadata": {},
   "source": [
    "Exercise 4 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22d8ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% VaR: 15,137.75\n",
      "95% ES: 23,473.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path = \"SP500_returns.xlsx\"  \n",
    "df = pd.read_excel(file_path)\n",
    "returns = df['r500'].dropna().values\n",
    "pos_val = 1000000  # 1 million\n",
    "alpha = 0.95\n",
    "# VaR\n",
    "var_95 = -np.percentile(returns, (1 - alpha) * 100) * pos_val\n",
    "# Expected Shortfall\n",
    "threshold = np.percentile(returns, (1 - alpha) * 100)\n",
    "es_95 = -returns[returns <= threshold].mean() * pos_val\n",
    "print(f\"95% VaR: {var_95:,.2f}\")\n",
    "print(f\"95% ES: {es_95:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b990ebf",
   "metadata": {},
   "source": [
    "Exercise 4 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1535c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Student-t parameters:\n",
      "df = 4.12, loc = 0.000510, scale = 0.007247\n",
      "\n",
      "        VaR 95%        ES 95%\n",
      "0  15828.114971  22848.765076\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, t\n",
    "\n",
    "alpha = 0.95 # confidence level\n",
    "pos_val = 1000000  # 1 million\n",
    "\n",
    "# Fit Student-t distribution\n",
    "df_t, loc_t, scale_t = t.fit(returns)  # ν, μ, s\n",
    "# 95% quantile for fitted t\n",
    "q_t = t.ppf(alpha, df_t, loc=loc_t, scale=scale_t) * pos_val\n",
    "# VaR\n",
    "VaR_t = q_t\n",
    "# ES \n",
    "q_std = t.ppf(alpha, df_t)\n",
    "g = t.pdf(q_std, df_t)\n",
    "ES_std = g * (df_t + q_std**2) / ((df_t - 1) * (1 - alpha))\n",
    "ES_t = loc_t + scale_t * ES_std * pos_val\n",
    "# Compare\n",
    "results = pd.DataFrame({\n",
    "    \"VaR 95%\": [VaR_t],\n",
    "    \"ES 95%\": [ES_t]\n",
    "})\n",
    "print(\"Fitted Student-t parameters:\")\n",
    "print(f\"df = {df_t:.2f}, loc = {loc_t:.6f}, scale = {scale_t:.6f}\\n\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2c6df",
   "metadata": {},
   "source": [
    "The results we obtain for 95% VaR and 95% ES are slightly higher than the results in part (a). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
